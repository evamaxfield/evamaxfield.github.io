<!DOCTYPE html><html domain="evamaxfield.github.io" lang="en"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="default-src 'self';object-src 'none';script-src 'self' 'sha256-Ky9qZOPnMhQV/s7Fdb9TYAOfU4KtWNqCZaFK8tSzXa0=' plausible.io;connect-src 'self' plausible.io;style-src 'unsafe-inline';img-src 'self' data:" http-equiv="Content-Security-Policy"><link href="/img/favicon/favicon-192x192.png?hash=882400933d" rel="icon" type="image/png"><meta content="#f9c412" name="theme-color"><title>Selected Papers</title><meta content="Selected Papers" property="og:title"><meta content="Please see my Semantic Scholar Profile for a complete list of my publications. Subject Matter # Public Interest Technology Research Software..." name="description"><meta content="Please see my Semantic Scholar Profile for a complete list of my publications. Subject Matter # Public Interest Technology Research Software..." property="og:description"><meta content="summary_large_image" name="twitter:card"><meta content="@evamaxfieldb" name="twitter:site"><meta content="@evamaxfieldb" name="twitter:creator"><link href="https://evamaxfield.github.io/papers/" rel="canonical"><meta content="no-referrer-when-downgrade" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="Eva Maxfield Brown"><link href="/" rel="preconnect" crossorigin=""><script defer="" src="/js/min.js?hash=54e8a28837" async=""></script><script defer="" src="https://plausible.io/js/plausible.hash.js" data-domain="evamaxfield.github.io"></script><script csp-hash="sha256-Ky9qZOPnMhQV/s7Fdb9TYAOfU4KtWNqCZaFK8tSzXa0=">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>:root{--primary: #ff4f5e;--primary-dark: #bd3b46;--main-width: calc(100vw - 3em)}main img{content-visibility:auto}header nav{z-index:1;position:fixed;top:0;left:0;width:100vw;padding:.375em 1.5em;background:rgba(255,255,255,.9);font-weight:200;text-align:right}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)}}dialog{background-color:#8dff80;position:fixed;opacity:.9}#nav,sub{position:relative}#nav{z-index:2}#reading-progress{z-index:1;background-color:var(--primary);width:100vw;position:absolute;left:0;top:0;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}#posts li{margin-bottom:.5em}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:100;src:url(/fonts/Inter-Thin.woff2) format("woff2"),url(/fonts/Inter-Thin.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:100;src:url(/fonts/Inter-ThinItalic.woff2) format("woff2"),url(/fonts/Inter-ThinItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:200;src:url(/fonts/Inter-ExtraLight.woff2) format("woff2"),url(/fonts/Inter-ExtraLight.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:200;src:url(/fonts/Inter-ExtraLightItalic.woff2) format("woff2"),url(/fonts/Inter-ExtraLightItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:300;src:url(/fonts/Inter-Light.woff2) format("woff2"),url(/fonts/Inter-Light.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:300;src:url(/fonts/Inter-LightItalic.woff2) format("woff2"),url(/fonts/Inter-LightItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:400;src:url(/fonts/Inter-Regular.woff2) format("woff2"),url(/fonts/Inter-Regular.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:400;src:url(/fonts/Inter-Italic.woff2) format("woff2"),url(/fonts/Inter-Italic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:500;src:url(/fonts/Inter-Medium.woff2) format("woff2"),url(/fonts/Inter-Medium.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:500;src:url(/fonts/Inter-MediumItalic.woff2) format("woff2"),url(/fonts/Inter-MediumItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:600;src:url(/fonts/Inter-SemiBold.woff2) format("woff2"),url(/fonts/Inter-SemiBold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:600;src:url(/fonts/Inter-SemiBoldItalic.woff2) format("woff2"),url(/fonts/Inter-SemiBoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:700;src:url(/fonts/Inter-Bold.woff2) format("woff2"),url(/fonts/Inter-Bold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:700;src:url(/fonts/Inter-BoldItalic.woff2) format("woff2"),url(/fonts/Inter-BoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:800;src:url(/fonts/Inter-ExtraBold.woff2) format("woff2"),url(/fonts/Inter-ExtraBold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:800;src:url(/fonts/Inter-ExtraBoldItalic.woff2) format("woff2"),url(/fonts/Inter-ExtraBoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:900;src:url(/fonts/Inter-Black.woff2) format("woff2"),url(/fonts/Inter-Black.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:900;src:url(/fonts/Inter-BlackItalic.woff2) format("woff2"),url(/fonts/Inter-BlackItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI var alt';font-weight:100 900;font-style:normal;font-named-instance:'Regular';src:url(/fonts/Inter-roman.var.woff2) format("woff2")}@font-face{font-display:swap;font-family:'Inter UI var alt';font-weight:100 900;font-style:italic;font-named-instance:'Italic';src:url(/fonts/Inter-italic.var.woff2) format("woff2")}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:3em;line-height:1.25;margin:.67em 0 .5em;font-size:2.074rem;line-height:2.4rem;margin-bottom:1.36rem}a{background-color:transparent;color:#f9c412;text-decoration:none;color:var(--primary)}b{font-weight:700}small{font-size:80%;color:#000}sub{font-size:75%;line-height:0;vertical-align:baseline;bottom:-.25em}header,img{margin:0 auto;max-width:100%}img{border-style:none;height:auto}h4{font-size:1.5em;margin-bottom:1em;line-height:1.5em}h4,h5{line-height:1.6rem}h5{line-height:1.5em;font-size:1.25em;margin-bottom:1.2em;font-size:1rem;margin-bottom:1.36rem}body,ol,p{font-size:1em}ol,p{margin-bottom:1.5em}h4{font-size:1.2rem}body,ol,p{font-size:1rem;line-height:1.6}h4,ol,p{margin-bottom:1.36rem}@media (min-width:600px){h1{font-size:4.3978rem;line-height:4.4rem}h4{font-size:1.5554rem}body,h5,ol,p{font-size:1.1rem}h4,h5{line-height:1.76rem}body,ol,p{line-height:1.6}h1,h4,h5,ol,p{margin-bottom:1.496rem}}@media (min-width:1200px){h1{font-size:6.0756rem;line-height:6.72rem}h4{font-size:1.8rem}body,h5,ol,p{font-size:1.2rem}h4,h5{line-height:1.92rem}body,ol,p{line-height:1.6}h1,h4,h5,ol,p{margin-bottom:1.632rem}}body,h1,h4,h5,header nav a,html{font-family:Inter UI,sans-serif}h4{font-style:italic}a:hover{text-decoration:underline}@media (max-width:767px){x:-moz-any-link{display:table-cell}}@supports (font-variation-settings:normal){html{font-family:Inter UI var alt,sans-serif}}*{border:0;box-sizing:border-box}body,header nav a{color:#000}body{background:#f9f4ec}header{padding:4.5em 1.5em 3em;width:37.5em;text-align:center;display:flex;align-items:center;flex-direction:column}header p,ol{margin-top:0}header nav h1{float:left;font-size:inherit;line-height:inherit;margin:0;text-align:left}header nav a{font-weight:700;text-decoration:none;margin-left:1.5em}header nav a:first-of-type{margin-left:auto}header nav a:last-of-type{margin-right:1.5em}main{max-width:70rem;margin:0 auto;border-top:1px dotted #000}footer{background:#e7e5e2;color:#000;padding:3em;text-align:left}footer>*{margin:1.5em}footer nav a img{vertical-align:middle}footer nav,footer p{font-size:90%}article{max-width:100%;padding:1.5em;width:37.5em;margin:0 auto}li ol{margin-bottom:0}</style></head><body><header><nav><div id="nav"><h1><a href="/" title="Homepage">Eva Maxfield Brown</a></h1><a href="/papers/">Selected Papers</a> <a href="/presentations/">Presentations</a> <a href="/software/">Software</a></div><div id="reading-progress" aria-hidden="true"></div></nav><h1>Selected Papers</h1><dialog id="message"></dialog></header><main><article><p>Please see my <a href="https://www.semanticscholar.org/author/Eva-Maxfield-Brown/2162029994">Semantic Scholar Profile</a> for a complete list of my publications.</p><h5 id="subject-matter">Subject Matter <a href="#subject-matter" class="direct-link">#</a></h5><ol><li><a href="#public-interest-technology">Public Interest Technology</a></li><li><a href="#research-software-engineering-and-applied-machine-learning">Research Software Engineering and Applied Machine Learning</a></li><li><a href="#computational-biology">Computational Biology</a></li></ol><h4 id="public-interest-technology">Public Interest Technology <a href="#public-interest-technology" class="direct-link">#</a></h4><h5 id="councils-in-action%3A-automating-the-curation-of-municipal-governance-data-for-research">Councils in Action: Automating the Curation of Municipal Governance Data for Research <a href="#councils-in-action%3A-automating-the-curation-of-municipal-governance-data-for-research" class="direct-link">#</a></h5><p>Eva Maxfield Brown and Nicholas Weber<br><em>ASIS&amp;T 2022 - published: 19 April 2022</em><br><a href="https://doi.org/10.1002/pra2.601">https://doi.org/10.1002/pra2.601</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-councils-in-action-split-discussion-trends-1920w.webp 1920w, /img/papers/cdp-councils-in-action-split-discussion-trends-1280w.webp 1280w, /img/papers/cdp-councils-in-action-split-discussion-trends-640w.webp 640w, /img/papers/cdp-councils-in-action-split-discussion-trends-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-councils-in-action-split-discussion-trends-1920w.jpg 1920w, /img/papers/cdp-councils-in-action-split-discussion-trends-1280w.jpg 1280w, /img/papers/cdp-councils-in-action-split-discussion-trends-640w.jpg 640w, /img/papers/cdp-councils-in-action-split-discussion-trends-320w.jpg 320w" type="image/jpeg"><img alt="Usage of different n-grams over time for all municipal councils covered in the initial release of the Councils In Action dataset" src="../img/papers/cdp-councils-in-action-split-discussion-trends.png" decoding="async" height="2034" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 2517px) min(calc(var(--main-width) * 0.8081048867699643), 2034px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 2517 2034'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAHCAYAAADam2dgAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAAk0lEQVQYlS2OwQ7DMAhD8/+/uXUlkEAS0rU7eQrtweIJLOxU68BODZk7RAZy7ijFY742hfuFpDrDxDLA4sFSHJQ73pvB5zKVBiFF4RbibDfvAibF97iQzCYyPQfpcajSg2mv8HEgVR34kILkjsnLXD3i136uT6p3yVV6ichiMvfgY5lGm7DS0dRDJg/bhJaB8/zhD0zF7kNzjzZDAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="2517"></picture></p><p><em>Large scale comparative research into municipal governance is often prohibitively difficult due to a lack of high-quality data. But, recent advances in speech-to-text algorithms and natural language processing has made it possible to more easily collect and analyze data about municipal governments. In this paper, we introduce an open-source platform, the Council Data Project (CDP), to curate novel datasets for research into municipal governance. The contribution of this work is two-fold: 1. We demonstrate that CDP, as an infrastructure, can be used to assemble reliable comparative data on municipal governance; 2. We provide exploratory analysis of three municipalities to show how CDP data can be used to gain insight into how municipal governments perform over time. We conclude by describing future directions for research on and with CDP such as the development of machine learning models for speaker annotation, outline generation, and named entity recognition for improved linked data.</em></p><h5 id="council-data-project%3A-software-for-municipal-data-collection%2C-analysis%2C-and-publication">Council Data Project: Software for Municipal Data Collection, Analysis, and Publication <a href="#council-data-project%3A-software-for-municipal-data-collection%2C-analysis%2C-and-publication" class="direct-link">#</a></h5><p>Eva Maxfield Brown, To Huynh, Isaac Na, Brian Ledbetter, Hawk Ticehurst, Sarah Liu, Emily Gilles, Katlyn M. F. Greene, Sung Cho, Shak Ragoler, Nicholas Weber<br><em>Journal of Open Source Software - published: 2 December 2021</em><br><a href="https://doi.org/10.21105/joss.03904">https://doi.org/10.21105/joss.03904</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-core-infra-1920w.webp 1920w, /img/papers/cdp-core-infra-1280w.webp 1280w, /img/papers/cdp-core-infra-640w.webp 640w, /img/papers/cdp-core-infra-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-core-infra-1920w.jpg 1920w, /img/papers/cdp-core-infra-1280w.jpg 1280w, /img/papers/cdp-core-infra-640w.jpg 640w, /img/papers/cdp-core-infra-320w.jpg 320w" type="image/jpeg"><img alt="council data project core event pipeline, video to audio to transcript to index" src="../img/papers/cdp-core-infra.png" decoding="async" height="869" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1599px) min(calc(var(--main-width) * 0.5434646654158849), 869px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1599 869'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAGCAYAAAAVMmT4AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAzklEQVQYlUWPPU/DMABE/f93RkZGJMSAxABDNz4UpU1VSmSqBiUkUcHBUeo4ceyHUoR40xtOpzuRV9+o9siM15rQqJPPHM3IW94w9JbJGES0a9mklimrUdEj5dMDfbKEj4xKW6IX4N3jN2vEOuvYlw6UYuhatEzp4xVOrTDFNbdFwtn2grI/IIbRA4GD7mks8Fljo5hRLgjqjufmlfPtJbX9Qvztk9VAuvd0S4m5ucIlMZ656B8RQjhJpSyqC7gixyzumXby97SfcH5izv0Afyr4CtkvUG0AAAAASUVORK5CYII='%3E%3C/image%3E%3C/svg%3E&quot;)" width="1599"></picture></p><p><em>Cities, counties, and states throughout the USA are bound by law to archive recordings of public meetings. Most local governments comply with these laws by posting documents, audio, or video recordings online. As there is no set standard for municipal data archives however, parsing and processing such data is typically time consuming and highly dependent on each municipality. Council Data Project (CDP) is a set of open-source tools that improve the accessibility of local government data by systematically collecting, transforming, and re-publishing this data to the web. The data re-published by CDP is packaged and presented within a searchable web application that vastly simplifies the process of finding specific information within the archived data. We envision this project being used by a variety of groups including civic technologists hoping to promote government transparency, researchers focused on public policy, natural language processing, machine learning, or information retrieval and discovery, and many others.</em></p><h4 id="research-software-engineering-and-applied-machine-learning">Research Software Engineering and Applied Machine Learning <a href="#research-software-engineering-and-applied-machine-learning" class="direct-link">#</a></h4><h5 id="soft-search%3A-two-datasets-to-study-the-identification-and-production-of-research-software">Soft-Search: Two Datasets to Study the Identification and Production of Research Software <a href="#soft-search%3A-two-datasets-to-study-the-identification-and-production-of-research-software" class="direct-link">#</a></h5><p>Eva Maxfield Brown, Lindsey Schwartz, Richard Lewei Huang, Nicholas Weber<br><em>In review for JCDL 2023 - pre-print published: 27 February 2023</em><br><a href="https://doi.org/10.48550/arXiv.2302.14177">https://doi.org/10.48550/arXiv.2302.14177</a></p><p><img alt="perecent of awards which likely produce software as NSF award duration increases" src="../img/papers/soft-search-award-duration.png"></p><p><em>Software is an important tool for scholarly work, but software produced for research is in many cases not easily identifiable or discoverable. A potential first step in linking research and software is software identification. In this paper we present two datasets to study the identification and production of research software. The first dataset contains almost 1000 human labeled annotations of software production from National Science Foundation (NSF) awarded research projects. We use this dataset to train models that predict software production. Our second dataset is created by applying the trained predictive models across the abstracts and project outcomes reports for all NSF funded projects between the years of 2010 and 2023. The result is an inferred dataset of software production for over 150,000 NSF awards. We release the Soft-Search dataset to aid in identifying and understanding research software production: <a href="https://github.com/si2-urssi/eager">https://github.com/si2-urssi/eager</a></em></p><h4 id="computational-biology">Computational Biology <a href="#computational-biology" class="direct-link">#</a></h4><h5 id="a-deep-generative-model-of-3d-single-cell-organization">A deep generative model of 3D single-cell organization <a href="#a-deep-generative-model-of-3d-single-cell-organization" class="direct-link">#</a></h5><p>Rory M. Donovan-Maiye, Eva M. Brown, Caleb K. Chan, Liya Ding, Calysta Yan, Nathalie Gaudreault, Julie A. Theriot, Mary M. Maleckar, Theo A. Knijnenburg, Gregory R. Johnson</p><p><em>PLOS Computational Biology -- published: 18 January 2022</em><br><a href="https://doi.org/10.1371/journal.pcbi.1009155">https://doi.org/10.1371/journal.pcbi.1009155</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/integrated-cell-1920w.webp 1920w, /img/papers/integrated-cell-1280w.webp 1280w, /img/papers/integrated-cell-640w.webp 640w, /img/papers/integrated-cell-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/integrated-cell-1920w.jpg 1920w, /img/papers/integrated-cell-1280w.jpg 1280w, /img/papers/integrated-cell-640w.jpg 640w, /img/papers/integrated-cell-320w.jpg 320w" type="image/jpeg"><img alt="cells generated using the integrated cell model using a range of beta values" src="../img/papers/integrated-cell.png" decoding="async" height="729" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 925px) min(calc(var(--main-width) * 0.7881081081081082), 729px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 925 729'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAHCAYAAADam2dgAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA2ElEQVQYlR3JXU+CUACA4TM8x/hwQVAKHJmo4XAjtEKtVlt209Y/U0jgF79tPbeP2FUf6HlGdl9SZAeKRcVm9U6ZVqzTLa/5FyJdPmE7CbFXEvuPTJwVM39PYq6JrZxtcEREE81QWLgqwJIjBsLAG/i4MsCVt4S2RiyzirFfkIef6HD3n4tgT+6/sb375hD+IKZRgjSuMJWNKz2kUthqxLXycOUNYydE6HiDVFOGUuOJGZHI0GbF3Hhmrl54cI6Ivu+pT2cuzS9NU9OdWvqmo2ta2vOFru74Az27Xp9knqH+AAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="925"></picture></p><p><em>We introduce a framework for end-to-end integrative modeling of 3D single-cell multi-channel fluorescent image data of diverse subcellular structures. We employ stacked conditional Î²-variational autoencoders to first learn a latent representation of cell morphology, and then learn a latent representation of subcellular structure localization which is conditioned on the learned cell morphology. Our model is flexible and can be trained on images of arbitrary subcellular structures and at varying degrees of sparsity and reconstruction fidelity. We train our full model on 3D cell image data and explore design trade-offs in the 2D setting. Once trained, our model can be used to predict plausible locations of structures in cells where these structures were not imaged. The trained model can also be used to quantify the variation in the location of subcellular structures by generating plausible instantiations of each structure in arbitrary cell geometries. We apply our trained model to a small drug perturbation screen to demonstrate its applicability to new data. We show how the latent representations of drugged cells differ from unperturbed cells as expected by on-target effects of the drugs.</em></p></article></main><footer><p>Email: <a href="mailto:evamxb@uw.edu">evamxb@uw.edu</a><br>Mastodon: <a href="https://social.ridetrans.it/@EvaMaxfield" rel="me">@EvaMaxfield@social.ridetrans.it</a><br>GitHub: <a href="https://github.com/evamaxfield">evamaxfield</a><br>ORCID: <a href="https://orcid.org/0000-0003-2564-0373">0000-0003-2564-0373</a><br>Semantic Scholar: <a href="https://www.semanticscholar.org/author/Eva-Maxfield-Brown/2162029994">Eva Maxfield Brown</a><br></p><sub>This website was created using <a href="https://www.industrialempathy.com/posts/eleventy-high-performance-blog/">eleventy-high-performance-blog</a>.</sub></footer></body></html>