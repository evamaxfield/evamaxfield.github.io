<!DOCTYPE html><html domain="evamaxfield.github.io" lang="en"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="default-src 'self';object-src 'none';script-src 'self' 'sha256-Ky9qZOPnMhQV/s7Fdb9TYAOfU4KtWNqCZaFK8tSzXa0=' plausible.io;connect-src 'self' plausible.io;style-src 'unsafe-inline';img-src 'self' data:" http-equiv="Content-Security-Policy"><link href="/img/favicon/favicon-192x192.png?hash=882400933d" rel="icon" type="image/png"><meta content="#f9c412" name="theme-color"><title>Papers</title><meta content="Papers" property="og:title"><meta content="Subject Matter # Public Interest Technology Data Archival Computational Biology Public Interest Technology # Councils in Action: Automating..." name="description"><meta content="Subject Matter # Public Interest Technology Data Archival Computational Biology Public Interest Technology # Councils in Action: Automating..." property="og:description"><meta content="summary_large_image" name="twitter:card"><meta content="@evamaxfieldb" name="twitter:site"><meta content="@evamaxfieldb" name="twitter:creator"><link href="https://evamaxfield.github.io/papers/" rel="canonical"><meta content="no-referrer-when-downgrade" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="Eva Maxfield Brown"><link href="/" rel="preconnect" crossorigin=""><script defer="" src="/js/min.js?hash=54e8a28837" async=""></script><script defer="" src="https://plausible.io/js/plausible.hash.js" data-domain="evamaxfield.github.io"></script><script csp-hash="sha256-Ky9qZOPnMhQV/s7Fdb9TYAOfU4KtWNqCZaFK8tSzXa0=">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>:root{--primary: #ff4f5e;--primary-dark: #bd3b46;--main-width: calc(100vw - 3em)}main img{content-visibility:auto}header nav{z-index:1;position:fixed;top:0;left:0;width:100vw;padding:.375em 1.5em;background:rgba(255,255,255,.9);font-weight:200;text-align:right}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)}}dialog{background-color:#8dff80;position:fixed;opacity:.9}#nav,sub{position:relative}#nav{z-index:2}#reading-progress{z-index:1;background-color:var(--primary);width:100vw;position:absolute;left:0;top:0;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}#posts li{margin-bottom:.5em}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:100;src:url(/fonts/Inter-Thin.woff2) format("woff2"),url(/fonts/Inter-Thin.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:100;src:url(/fonts/Inter-ThinItalic.woff2) format("woff2"),url(/fonts/Inter-ThinItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:200;src:url(/fonts/Inter-ExtraLight.woff2) format("woff2"),url(/fonts/Inter-ExtraLight.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:200;src:url(/fonts/Inter-ExtraLightItalic.woff2) format("woff2"),url(/fonts/Inter-ExtraLightItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:300;src:url(/fonts/Inter-Light.woff2) format("woff2"),url(/fonts/Inter-Light.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:300;src:url(/fonts/Inter-LightItalic.woff2) format("woff2"),url(/fonts/Inter-LightItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:400;src:url(/fonts/Inter-Regular.woff2) format("woff2"),url(/fonts/Inter-Regular.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:400;src:url(/fonts/Inter-Italic.woff2) format("woff2"),url(/fonts/Inter-Italic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:500;src:url(/fonts/Inter-Medium.woff2) format("woff2"),url(/fonts/Inter-Medium.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:500;src:url(/fonts/Inter-MediumItalic.woff2) format("woff2"),url(/fonts/Inter-MediumItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:600;src:url(/fonts/Inter-SemiBold.woff2) format("woff2"),url(/fonts/Inter-SemiBold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:600;src:url(/fonts/Inter-SemiBoldItalic.woff2) format("woff2"),url(/fonts/Inter-SemiBoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:700;src:url(/fonts/Inter-Bold.woff2) format("woff2"),url(/fonts/Inter-Bold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:700;src:url(/fonts/Inter-BoldItalic.woff2) format("woff2"),url(/fonts/Inter-BoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:800;src:url(/fonts/Inter-ExtraBold.woff2) format("woff2"),url(/fonts/Inter-ExtraBold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:800;src:url(/fonts/Inter-ExtraBoldItalic.woff2) format("woff2"),url(/fonts/Inter-ExtraBoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:900;src:url(/fonts/Inter-Black.woff2) format("woff2"),url(/fonts/Inter-Black.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:900;src:url(/fonts/Inter-BlackItalic.woff2) format("woff2"),url(/fonts/Inter-BlackItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI var alt';font-weight:100 900;font-style:normal;font-named-instance:'Regular';src:url(/fonts/Inter-roman.var.woff2) format("woff2")}@font-face{font-display:swap;font-family:'Inter UI var alt';font-weight:100 900;font-style:italic;font-named-instance:'Italic';src:url(/fonts/Inter-italic.var.woff2) format("woff2")}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:3em;line-height:1.25;margin:.67em 0 .5em;font-size:2.074rem;line-height:2.4rem;margin-bottom:1.36rem}a{background-color:transparent;color:#f9c412;text-decoration:none;color:var(--primary)}b{font-weight:700}small{font-size:80%;color:#000}sub{font-size:75%;line-height:0;vertical-align:baseline;bottom:-.25em}header,img{margin:0 auto;max-width:100%}img{border-style:none;height:auto}h4{font-size:1.5em;margin-bottom:1em;line-height:1.5em}h4,h5{line-height:1.6rem}h5{line-height:1.5em;font-size:1.25em;margin-bottom:1.2em;font-size:1rem;margin-bottom:1.36rem}body,ol,p{font-size:1em}ol,p{margin-bottom:1.5em}h4{font-size:1.2rem}body,ol,p{font-size:1rem;line-height:1.6}h4,ol,p{margin-bottom:1.36rem}@media (min-width:600px){h1{font-size:4.3978rem;line-height:4.4rem}h4{font-size:1.5554rem}body,h5,ol,p{font-size:1.1rem}h4,h5{line-height:1.76rem}body,ol,p{line-height:1.6}h1,h4,h5,ol,p{margin-bottom:1.496rem}}@media (min-width:1200px){h1{font-size:6.0756rem;line-height:6.72rem}h4{font-size:1.8rem}body,h5,ol,p{font-size:1.2rem}h4,h5{line-height:1.92rem}body,ol,p{line-height:1.6}h1,h4,h5,ol,p{margin-bottom:1.632rem}}body,h1,h4,h5,header nav a,html{font-family:Inter UI,sans-serif}h4{font-style:italic}a:hover{text-decoration:underline}@media (max-width:767px){x:-moz-any-link{display:table-cell}}@supports (font-variation-settings:normal){html{font-family:Inter UI var alt,sans-serif}}*{border:0;box-sizing:border-box}body,header nav a{color:#000}body{background:#f9f4ec}header{padding:4.5em 1.5em 3em;width:37.5em;text-align:center;display:flex;align-items:center;flex-direction:column}header p,ol{margin-top:0}header nav h1{float:left;font-size:inherit;line-height:inherit;margin:0;text-align:left}header nav a{font-weight:700;text-decoration:none;margin-left:1.5em}header nav a:first-of-type{margin-left:auto}header nav a:last-of-type{margin-right:1.5em}main{max-width:70rem;margin:0 auto;border-top:1px dotted #000}footer{background:#e7e5e2;color:#000;padding:3em;text-align:left}footer>*{margin:1.5em}footer nav a img{vertical-align:middle}footer nav,footer p{font-size:90%}article{max-width:100%;padding:1.5em;width:37.5em;margin:0 auto}li ol{margin-bottom:0}</style></head><body><header><nav><div id="nav"><h1><a href="/" title="Homepage">Eva Maxfield Brown</a></h1><a href="/papers/">Papers</a> <a href="/presentations/">Presentations</a> <a href="/software/">Software</a></div><div id="reading-progress" aria-hidden="true"></div></nav><h1>Papers</h1><dialog id="message"></dialog></header><main><article><h5 id="subject-matter">Subject Matter <a href="#subject-matter" class="direct-link">#</a></h5><ol><li><a href="#public-interest-technology">Public Interest Technology</a></li><li><a href="#data-archival">Data Archival</a></li><li><a href="#computational-biology">Computational Biology</a></li></ol><h4 id="public-interest-technology">Public Interest Technology <a href="#public-interest-technology" class="direct-link">#</a></h4><h5 id="councils-in-action%3A-automating-the-curation-of-municipal-governance-data-for-research">Councils in Action: Automating the Curation of Municipal Governance Data for Research <a href="#councils-in-action%3A-automating-the-curation-of-municipal-governance-data-for-research" class="direct-link">#</a></h5><p>Eva Maxfield Brown and Nicholas Weber<br><em>in review for ASIS&amp;T 2022 - preprint published: 21 April 2022</em><br><a href="https://doi.org/10.48550/arXiv.2204.09110">https://doi.org/10.48550/arXiv.2204.09110</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-councils-in-action-split-discussion-trends-1920w.webp 1920w, /img/papers/cdp-councils-in-action-split-discussion-trends-1280w.webp 1280w, /img/papers/cdp-councils-in-action-split-discussion-trends-640w.webp 640w, /img/papers/cdp-councils-in-action-split-discussion-trends-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-councils-in-action-split-discussion-trends-1920w.jpg 1920w, /img/papers/cdp-councils-in-action-split-discussion-trends-1280w.jpg 1280w, /img/papers/cdp-councils-in-action-split-discussion-trends-640w.jpg 640w, /img/papers/cdp-councils-in-action-split-discussion-trends-320w.jpg 320w" type="image/jpeg"><img alt="Usage of different n-grams over time for all municipal councils covered in the initial release of the Councils In Action dataset" decoding="async" height="2034" loading="lazy" src="../img/papers/cdp-councils-in-action-split-discussion-trends.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 2517px) min(calc(var(--main-width) * 0.8081048867699643), 2034px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 2517 2034'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAHCAYAAADam2dgAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAAk0lEQVQYlS2OwQ7DMAhD8/+/uXUlkEAS0rU7eQrtweIJLOxU68BODZk7RAZy7ijFY742hfuFpDrDxDLA4sFSHJQ73pvB5zKVBiFF4RbibDfvAibF97iQzCYyPQfpcajSg2mv8HEgVR34kILkjsnLXD3i136uT6p3yVV6ichiMvfgY5lGm7DS0dRDJg/bhJaB8/zhD0zF7kNzjzZDAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="2517"></picture></p><p><em>Large scale comparative research into municipal governance is often prohibitively difficult due to a lack of high-quality data. But, recent advances in speech-to-text algorithms and natural language processing has made it possible to more easily collect and analyze data about municipal governments. In this paper, we introduce an open-source platform, the Council Data Project (CDP), to curate novel datasets for research into municipal governance. The contribution of this work is two-fold: 1. We demonstrate that CDP, as an infrastructure, can be used to assemble reliable comparative data on municipal governance; 2. We provide exploratory analysis of three municipalities to show how CDP data can be used to gain insight into how municipal governments perform over time. We conclude by describing future directions for research on and with CDP such as the development of machine learning models for speaker annotation, outline generation, and named entity recognition for improved linked data.</em></p><h5 id="integrative-urban-ai-to-expand-coverage%2C-access%2C-and-equity-of-urban-data">Integrative Urban AI to Expand Coverage, Access, and Equity of Urban Data <a href="#integrative-urban-ai-to-expand-coverage%2C-access%2C-and-equity-of-urban-data" class="direct-link">#</a></h5><p>Bill Howe, Eva Maxfield Brown, Bin Han, Bernease Herman, Nic Weber, An Yan, Sean Yang, and Yiwei Yang<br><em>The European Physical Journal Special Topics - published: 9 April 2022</em><br><a href="https://doi.org/10.1140/epjs/s11734-022-00475-z">https://doi.org/10.1140/epjs/s11734-022-00475-z</a></p><p><em>We consider the use of AI techniques to expand the coverage, access, and equity of urban data. We aim to enable holistic research on city dynamics, steering AI research attention away from profit-oriented, societally harmful applications (e.g., facial recognition) and toward foundational questions in mobility, participatory governance, and justice. By making available high-quality, multi-variate, cross-scale data for research, we aim to link the macrostudy of cities as complex systems with the reductionist view of cities as an assembly of independent prediction tasks. We identify four research areas in AI for cities as key enablers: interpolation and extrapolation of spatiotemporal data, using NLP techniques to model speech- and text-intensive governance activities, exploiting ontology modeling in learning tasks, and understanding the interaction of fairness and interpretability in sensitive contexts.</em></p><h5 id="council-data-project%3A-software-for-municipal-data-collection%2C-analysis%2C-and-publication">Council Data Project: Software for Municipal Data Collection, Analysis, and Publication <a href="#council-data-project%3A-software-for-municipal-data-collection%2C-analysis%2C-and-publication" class="direct-link">#</a></h5><p>Eva Maxfield Brown, To Huynh, Isaac Na, Brian Ledbetter, Hawk Ticehurst, Sarah Liu, Emily Gilles, Katlyn M. F. Greene, Sung Cho, Shak Ragoler, Nicholas Weber<br><em>Journal of Open Source Software - published: 2 December 2021</em><br><a href="https://doi.org/10.21105/joss.03904">https://doi.org/10.21105/joss.03904</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-core-infra-1920w.webp 1920w, /img/papers/cdp-core-infra-1280w.webp 1280w, /img/papers/cdp-core-infra-640w.webp 640w, /img/papers/cdp-core-infra-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/cdp-core-infra-1920w.jpg 1920w, /img/papers/cdp-core-infra-1280w.jpg 1280w, /img/papers/cdp-core-infra-640w.jpg 640w, /img/papers/cdp-core-infra-320w.jpg 320w" type="image/jpeg"><img alt="council data project core event pipeline, video to audio to transcript to index" decoding="async" height="869" loading="lazy" src="../img/papers/cdp-core-infra.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1599px) min(calc(var(--main-width) * 0.5434646654158849), 869px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1599 869'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAGCAYAAAAVMmT4AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAzklEQVQYlUWPPU/DMABE/f93RkZGJMSAxABDNz4UpU1VSmSqBiUkUcHBUeo4ceyHUoR40xtOpzuRV9+o9siM15rQqJPPHM3IW94w9JbJGES0a9mklimrUdEj5dMDfbKEj4xKW6IX4N3jN2vEOuvYlw6UYuhatEzp4xVOrTDFNbdFwtn2grI/IIbRA4GD7mks8Fljo5hRLgjqjufmlfPtJbX9Qvztk9VAuvd0S4m5ucIlMZ656B8RQjhJpSyqC7gixyzumXby97SfcH5izv0Afyr4CtkvUG0AAAAASUVORK5CYII='%3E%3C/image%3E%3C/svg%3E&quot;)" width="1599"></picture></p><p><em>Cities, counties, and states throughout the USA are bound by law to archive recordings of public meetings. Most local governments comply with these laws by posting documents, audio, or video recordings online. As there is no set standard for municipal data archives however, parsing and processing such data is typically time consuming and highly dependent on each municipality. Council Data Project (CDP) is a set of open-source tools that improve the accessibility of local government data by systematically collecting, transforming, and re-publishing this data to the web. The data re-published by CDP is packaged and presented within a searchable web application that vastly simplifies the process of finding specific information within the archived data. We envision this project being used by a variety of groups including civic technologists hoping to promote government transparency, researchers focused on public policy, natural language processing, machine learning, or information retrieval and discovery, and many others.</em></p><h5 id="packaging-municipal-legislative-event-data-for-reuse-and-exchange">Packaging Municipal Legislative Event Data for Reuse and Exchange <a href="#packaging-municipal-legislative-event-data-for-reuse-and-exchange" class="direct-link">#</a></h5><p>Eva Brown and Nic Weber<br><em>Workshop on Research Objects - published: 28 August 2019</em><br><a href="https://doi.org/10.5281/zenodo.3380592">https://doi.org/10.5281/zenodo.3380592</a></p><p><em>Municipal governments in the USA are often divided between a legislative (city council) and executive (mayoral) branch. These two branches not only differ in their power to govern a municipality, but also in the way their governing activities are organized: executive activities are periodic and random in occurrence, legislative activities are regularly occurring and organized around key events (e.g. committee and subcommittee meetings, expert testimony, public comment, introduction and debate of new legislation, and voting). Further, legislative events are subject to Open Meetings laws at both the State and Federal level - so that citizens can have a transparent record of how officials are performing their elected duties. This openness mandate further requires that the events of any municipal legislature are recorded and published to the web in an openly accessible format. However, many municipal governments lack the time, money, and expertise to provide citizens with well described data beyond a simple audio or video file of a legislative event. The Council Data Project (CDP) is our attempt to provide a platform for adding needed context to event based legislative data. In particular we provide open-source tools for transcribing, indexing, modeling, and publishing legislative event data to the web. Our on-going research is focused on how to package a bundle of event-based digital objects (audio-files, videos, transcripts, votes, etc) along with relevant metadata parameters to facilitate meaningful reuse by researchers.</em></p><h4 id="data-archival">Data Archival <a href="#data-archival" class="direct-link">#</a></h4><h5 id="dsdb%3A-an-open-source-system-for-dataset-versioning-%26-curation">DSDB: An Open-Source System for Dataset Versioning &amp; Curation <a href="#dsdb%3A-an-open-source-system-for-dataset-versioning-%26-curation" class="direct-link">#</a></h5><p>Eva Brown and Nic Weber<br><em>Joint Conference on Digital Libraries - published: 27 September 2021</em><br><a href="https://doi.org/10.1109/JCDL52503.2021.00044">https://doi.org/10.1109/JCDL52503.2021.00044</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/dsdb-1920w.webp 1920w, /img/papers/dsdb-1280w.webp 1280w, /img/papers/dsdb-640w.webp 640w, /img/papers/dsdb-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/dsdb-1920w.jpg 1920w, /img/papers/dsdb-1280w.jpg 1280w, /img/papers/dsdb-640w.jpg 640w, /img/papers/dsdb-320w.jpg 320w" type="image/jpeg"><img alt="workflow of how dataset database breaks down datasets to groups and iota" decoding="async" height="429" loading="lazy" src="../img/papers/dsdb.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 804px) min(calc(var(--main-width) * 0.5335820895522388), 429px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 804 429'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAGCAYAAAAVMmT4AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA8ElEQVQYlS2PMUvDQABG3+VME2KuSXoITnV1aAc76OBssUUItSCIuAq6OCm4NwGp4KCb4H/p5uQiFBFEHPS0q6UUij2pOnzwhje8D8AHFv/nI4Q8EgIL9KopvFvaZ30amYEKqBqoCkRVCB3wrF5iAsHdct3FWlonD6KZG48BqFeIX6A0cJz5J6WUhWgKOtu9SdavvoM0f4sbmYkZQXEEyRj0V6GghuWytqAnzly4f3ofbZ1/Rttds7DZMSEt8FMINiBsgxfMMqQrhiC7O9eydjkVKwePNPMPCVAEEqD0y1K6h/wd7OzdsnYxZvX4eSbzA1CqQFPt7lAfAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="804"></picture></p><p><em>In the following poster we describe the design and evaluation of DatasetDatabase (DSDB), an open-source system for handling the provenance, versioning, de-duplication, history, and query of dynamic datasets in order to enable verifiable and shareable results - features necessary for fully reproducible computational modeling research. We present empirical work that motivates an initial design and deployment of DSDB, evaluate the results of this work for computational modeling at the Allen Institute for Cell Science, and conclude with a discussion of the future work necessary for provisioning data discovery and sharing tools that facilitate transparent reproducible research through provenance aware features..</em></p><h5 id="managing-manifests-and-distributing-datasets">Managing Manifests and Distributing Datasets <a href="#managing-manifests-and-distributing-datasets" class="direct-link">#</a></h5><p>Eva Brown<br><em>Workshop on Research Objects - published: 30 August 2019</em><br><a href="https://doi.org/10.5281/zenodo.3382258">https://doi.org/10.5281/zenodo.3382258</a></p><p><em>A core principal of research is the affordability and ease of reproducing the results found by an experiment and to minimize the challenge of experimental reproducibility, it is common for researchers to share the dataset used to produce the results of an experiment. Methods for managing and distributing these datasets however, are ill-suited for imaging datasets, or more generally: large object datasets, because they commonly resemble a manifest and require additional packaging and organization than their feature set counterparts. Quilt3Distribute (Q3D) is a software application that enables the distribution of manifest style datasets which can be made of up thousands of individual files.</em></p><h4 id="computational-biology">Computational Biology <a href="#computational-biology" class="direct-link">#</a></h4><h5 id="a-deep-generative-model-of-3d-single-cell-organization">A deep generative model of 3D single-cell organization <a href="#a-deep-generative-model-of-3d-single-cell-organization" class="direct-link">#</a></h5><p>Rory M. Donovan-Maiye, Eva M. Brown, Caleb K. Chan, Liya Ding, Calysta Yan, Nathalie Gaudreault, Julie A. Theriot, Mary M. Maleckar, Theo A. Knijnenburg, Gregory R. Johnson</p><p><em>PLOS Computational Biology -- published: 18 January 2022</em><br><a href="https://doi.org/10.1371/journal.pcbi.1009155">https://doi.org/10.1371/journal.pcbi.1009155</a></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/integrated-cell-1920w.webp 1920w, /img/papers/integrated-cell-1280w.webp 1280w, /img/papers/integrated-cell-640w.webp 640w, /img/papers/integrated-cell-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/papers/integrated-cell-1920w.jpg 1920w, /img/papers/integrated-cell-1280w.jpg 1280w, /img/papers/integrated-cell-640w.jpg 640w, /img/papers/integrated-cell-320w.jpg 320w" type="image/jpeg"><img alt="cells generated using the integrated cell model using a range of beta values" decoding="async" height="729" loading="lazy" src="../img/papers/integrated-cell.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 925px) min(calc(var(--main-width) * 0.7881081081081082), 729px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 925 729'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAHCAYAAADam2dgAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA2ElEQVQYlR3JXU+CUACA4TM8x/hwQVAKHJmo4XAjtEKtVlt209Y/U0jgF79tPbeP2FUf6HlGdl9SZAeKRcVm9U6ZVqzTLa/5FyJdPmE7CbFXEvuPTJwVM39PYq6JrZxtcEREE81QWLgqwJIjBsLAG/i4MsCVt4S2RiyzirFfkIef6HD3n4tgT+6/sb375hD+IKZRgjSuMJWNKz2kUthqxLXycOUNYydE6HiDVFOGUuOJGZHI0GbF3Hhmrl54cI6Ivu+pT2cuzS9NU9OdWvqmo2ta2vOFru74Az27Xp9knqH+AAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="925"></picture></p><p><em>We introduce a framework for end-to-end integrative modeling of 3D single-cell multi-channel fluorescent image data of diverse subcellular structures. We employ stacked conditional β-variational autoencoders to first learn a latent representation of cell morphology, and then learn a latent representation of subcellular structure localization which is conditioned on the learned cell morphology. Our model is flexible and can be trained on images of arbitrary subcellular structures and at varying degrees of sparsity and reconstruction fidelity. We train our full model on 3D cell image data and explore design trade-offs in the 2D setting. Once trained, our model can be used to predict plausible locations of structures in cells where these structures were not imaged. The trained model can also be used to quantify the variation in the location of subcellular structures by generating plausible instantiations of each structure in arbitrary cell geometries. We apply our trained model to a small drug perturbation screen to demonstrate its applicability to new data. We show how the latent representations of drugged cells differ from unperturbed cells as expected by on-target effects of the drugs.</em></p><h5 id="cell-states-beyond-transcriptomics%3A-integrating-structural-organization-and-gene-expression-in-hipsc-derived-cardiomyocytes">Cell states beyond transcriptomics: integrating structural organization and gene expression in hiPSC-derived cardiomyocytes <a href="#cell-states-beyond-transcriptomics%3A-integrating-structural-organization-and-gene-expression-in-hipsc-derived-cardiomyocytes" class="direct-link">#</a></h5><p>Gerbin, Grancharova, Donovan-Maiye, Hendershott, et al.<br><em>Cell - published: 26 May 2021</em><br><a href="https://doi.org/10.1016/j.cels.2021.05.001">https://doi.org/10.1016/j.cels.2021.05.001</a></p><p><em>Although some cell types may be defined anatomically or by physiological function, a rigorous definition of cell state remains elusive. Here, we develop a quantitative, imaging-based platform for the systematic and automated classification of subcellular organization in single cells. We use this platform to quantify subcellular organization and gene expression in &gt;30,000 individual human induced pluripotent stem cell-derived cardiomyocytes, producing a publicly available dataset that describes the population distributions of local and global sarcomere organization, mRNA abundance, and correlations between these traits. While the mRNA abundance of some phenotypically important genes correlates with subcellular organization (e.g., the beta-myosin heavy chain, MYH7), these two cellular metrics are heterogeneous and often uncorrelated, which suggests that gene expression alone is not sufficient to classify cell states. Instead, we posit that cell state should be defined by observing full distributions of quantitative, multidimensional traits in single cells that also account for space, time, and function.</em></p><h5 id="robust-integrated-intracellular-organization-of-the-human-ips-cell%3A-where%2C-how-much%2C-and-how-variable%3F">Robust integrated intracellular organization of the human iPS cell: where, how much, and how variable? <a href="#robust-integrated-intracellular-organization-of-the-human-ips-cell%3A-where%2C-how-much%2C-and-how-variable%3F" class="direct-link">#</a></h5><p>Viana, et al.<br><em>preprint published: 10 December 2020</em><br><a href="https://doi.org/10.1101/2020.12.08.415562">https://doi.org/10.1101/2020.12.08.415562</a></p><p><em>Despite the intimate link between cell organization and function, the principles underlying intracellular organization and the relation between organization, gene expression and phenotype are not well understood. We address this by creating a benchmark for mean cell organization and the natural range of cell-to-cell variation. This benchmark can be used for comparison to other normal or abnormal cell states. To do this, we developed a reproducible microscope imaging pipeline to generate a high quality dataset of 3D, high-resolution images of over 200,000 live cells from 25 isogenic human induced pluripotent stem cell (hiPSC) lines from the Allen Cell Collection. Each line contains one fluorescently tagged protein, created via endogenous CRISPR/Cas9 gene editing, representing a key cellular structure or organelle. We used these images to develop a new multi-part generalizable analysis approach of the locations, amounts, and variation of the 25 cellular structures. Taking an integrated approach, we found that both the extent to which a structure’s individual location varied (“stereotypy”) and the extent to which the structure localized relative to all the other cellular structures (“concordance”) were robust to a wide range of cell shape variation, from flatter to taller, smaller to larger, or less to more polarized cells. We also found that these cellular structures varied greatly in how their volumes scaled with cell and nuclear size. These analyses create a data-driven set of quantitative rules for the locations, amounts, and variation of 25 cellular structures within the hiPSC as a normal baseline for cell organization.</em></p></article></main><footer><p>Email: <a href="mailto:evamxb@uw.edu">evamxb@uw.edu</a><br>Mastodon: <a href="https://social.ridetrans.it/@EvaMaxfield" rel="me">@EvaMaxfield@social.ridetrans.it</a><br>GitHub: <a href="https://github.com/evamaxfield">evamaxfield</a><br>ORCID: <a href="https://orcid.org/0000-0003-2564-0373">0000-0003-2564-0373</a><br>Semantic Scholar: <a href="https://www.semanticscholar.org/author/Eva-Maxfield-Brown/2162029994">Eva Maxfield Brown</a><br></p><sub>This website was created using <a href="https://www.industrialempathy.com/posts/eleventy-high-performance-blog/">eleventy-high-performance-blog</a>.</sub></footer></body></html>